# 2025-02-10 (6주차 월요일) 회고

## Review

> * Dano Lee 강사님께서 6주차 첫번째 강의를 진행하셨다.

(따로 정리해 놓은 문서가 있어 여기에는 중요한 내용만 몇개 적도록 하겠다.)

Spark Job을 최적화 해야 한다.

Data를 알아야 한다.
* Data의 특성에 대한 이해를 통해 비로소 pyspark 코드를 효율적으로 작성할 수 있다.

불필요한 셔플이 발생하지 않도록 하자.
* Data의 특성에 맞게 적절한 파티셔닝을 수행하여 연산이 최대한 대상이 되는 데이터와 같은 지역에서 이뤄지도록 하자.

Hadoop, Spark에 대해 조만간 다시 개념 정리를 해야겠다.

> * 메인 프로젝트를 진행하였다.

내일까지 AWS 서비스들을 이용하여 아키텍쳐를 실행해 보는 iteration을 1회 진행하는 것을 목표로,
오늘은 EMR 클러스터를 실행해서 간단한 Spark Job을 실행해 보고 Redshift에 대한 입출력을 시도해 봤다.

2가지 이슈가 있었다..

* EMR의 결과를 확인하기 위해 18080 포트를 열어 Job History Server Web UI를 보고자 했는데, 보안 그룹에서 포트를 개방하니 처음엔 접속이 되었다가 곧이어 개방되었던 포트가 보안 그룹에서 사라졌다.
  * 이후 AWS에서 자동으로 Dangle 강사님께 경고 메일을 발송한 것 같다...
  * Spark의 작업 결과만을 보여주는 UI기 때문에 안전할 것이라 생각하여 포트를 개방하였지만, 결과적으로 EMR에서는 자동으로 해당 포트를 다시 차단하였다.
  * 보안에 더욱 신경을 써야겠다는 생각이 다시금 들었다.

* Lambda를 통해 Redshift에 대한 I/O를 수행하는 파이썬 예제 코드를 실행하고자 했는데 권한이 없어 해내지 못했다.
  * 내일 AWS 강의가 있으니 이 부분에 대해 여쭤봐야겠다.

## Keep

* 데일리 스크럼을 통해 할 일을 정한 뒤 계획대로 수행하기

## Problem

* 오후 3시 쯤부터 정신이 혼미해진다..

## Try

* 아침에 커피를 마시는 대신 점심 식사를 한 뒤 커피를 마시자.